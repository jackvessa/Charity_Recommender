{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(text_corpus):\n",
    "    '''\n",
    "    '''\n",
    "    # Create a set of frequent words\n",
    "    stoplist = \"\"\n",
    "    stoplist = set('for a of the and to in is'.split(' '))\n",
    "    \n",
    "    # Lowercase each document, split it by white space and filter out stopwords\n",
    "    texts = \"\"\n",
    "    texts = [[word for word in document.lower().split() if word not in stoplist] for document in text_corpus]\n",
    "    \n",
    "    # Count word frequencies\n",
    "    frequency = defaultdict(int)\n",
    "    \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency[token] += 1\n",
    "\n",
    "    # Only keep words that appear more than once\n",
    "    processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "    \n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_from_corpus(processed_corpus):\n",
    "    '''\n",
    "    '''\n",
    "    dictionary = corpora.Dictionary(processed_corpus)\n",
    "    features = (len(dictionary))\n",
    "    \n",
    "    bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "    \n",
    "    # train the model\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    \n",
    "    index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=features)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_charities(train_df,test_df):\n",
    "    '''\n",
    "    '''\n",
    "    total = 0\n",
    "    category_counter = {1:0,2:0,3:0}\n",
    "    \n",
    "    print(\"1. Processing Training Corpus\")\n",
    "    char_desc_trimmed = []\n",
    "    for doc in train_df['description']:\n",
    "        if len(doc) >= 200:\n",
    "            char_desc_trimmed.append(doc)\n",
    "    char_desc_trimmed = np.array(char_desc_trimmed)\n",
    "    \n",
    "    corpus = char_desc_trimmed\n",
    "    processed_corpus = process_corpus(corpus)\n",
    "    \n",
    "    print(\"2. Creating Index from Training Corpus\")\n",
    "    index = create_index_from_corpus(processed_corpus)\n",
    "    \n",
    "    print(\"3. Starting Test Corpus Similarity Analysis\\n\")\n",
    "    for ind, document in enumerate(test_df['description']):\n",
    "        total +=1 \n",
    "        \n",
    "        #print(\"Top 3 Charities Similar to:\", test_df['name'].iloc[ind],'\\n')\n",
    "        \n",
    "        query_bow = dictionary.doc2bow(document.split())\n",
    "        sims = index[tfidf[query_bow]]\n",
    "        \n",
    "        top_3_sim = dict()\n",
    "        count = 3\n",
    "        \n",
    "        for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "            if count > 0:\n",
    "                top_3_sim[document_number] = score\n",
    "            count -= 1\n",
    "            \n",
    "        category_count = 1\n",
    "        for doc, score in top_3_sim.items():\n",
    "            #print(charity_navigator_df['name'][doc])\n",
    "            #print(charity_navigator_df['description'][doc])\n",
    "            #print(doc, score, \"\\n\")\n",
    "            \n",
    "            # print (charity_navigator_df['category'][doc])\n",
    "            # print (test_df['category'].iloc[ind])\n",
    "            \n",
    "            if charity_navigator_df['category'][doc] == test_df['category'].iloc[ind]:\n",
    "                category_counter[category_count] += 1\n",
    "            category_count +=1\n",
    "            \n",
    "    # Print Scores\n",
    "    \n",
    "    first_rec_score = round((category_counter[1] / total)*100,2)\n",
    "    second_rec_score = round((category_counter[2] / total)*100,2)\n",
    "    third_rec_score = round((category_counter[3] / total)*100,2)\n",
    "    \n",
    "    print (\"First Recommendation Score:\", first_rec_score,\"%\")\n",
    "    print (\"Second Recommendation Score:\", second_rec_score,\"%\")   \n",
    "    print (\"Third Recommendation Score:\", third_rec_score,\"%\\n\")\n",
    "    \n",
    "    print (\"AVG Recommendation Score:\", (math.round((first_rec_score+second_rec_score+third_rec_score)/3),2),\"%\\n\")\n",
    "    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Charity Navigator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "charity_navigator_df = pd.read_csv('../data/CLEAN_charity_data.csv')\n",
    "charity_navigator_df = charity_navigator_df[['name','ein','category','description','motto','score','state']]\n",
    "charity_navigator_df['ein'] = charity_navigator_df['ein'].apply(lambda x: int(x.replace(\"-\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ein</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>motto</th>\n",
       "      <th>score</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000 Friends of Oregon</td>\n",
       "      <td>930642086</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Working with Oregonians to enhance our quality...</td>\n",
       "      <td>Great communities. Working lands. Iconic Places.</td>\n",
       "      <td>91.94</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WYPR</td>\n",
       "      <td>311770828</td>\n",
       "      <td>Arts, Culture, Humanities</td>\n",
       "      <td>Serving the metropolitan Baltimore area and th...</td>\n",
       "      <td>88.1 FM -. Your NPR News Station</td>\n",
       "      <td>85.59</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>VSS Catholic Communications</td>\n",
       "      <td>911857425</td>\n",
       "      <td>Religion</td>\n",
       "      <td>VSS Catholic Communications is dedicated to an...</td>\n",
       "      <td>Spirit Catholic Radio Network</td>\n",
       "      <td>76.80</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Utah Symphony &amp; Opera</td>\n",
       "      <td>510145980</td>\n",
       "      <td>Arts, Culture, Humanities</td>\n",
       "      <td>The mission of the Utah Symphony &amp; Opera is to...</td>\n",
       "      <td>Engaging, educating, and enriching lives</td>\n",
       "      <td>91.95</td>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Two Ten Footwear Foundation</td>\n",
       "      <td>222579809</td>\n",
       "      <td>Human Services</td>\n",
       "      <td>Funded solely by the footwear industry, Two Te...</td>\n",
       "      <td>Shoepeople Helping Shoepeople</td>\n",
       "      <td>90.26</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name        ein                   category  \\\n",
       "0       1000 Friends of Oregon  930642086                Environment   \n",
       "1                         WYPR  311770828  Arts, Culture, Humanities   \n",
       "2  VSS Catholic Communications  911857425                   Religion   \n",
       "3        Utah Symphony & Opera  510145980  Arts, Culture, Humanities   \n",
       "4  Two Ten Footwear Foundation  222579809             Human Services   \n",
       "\n",
       "                                         description  \\\n",
       "0  Working with Oregonians to enhance our quality...   \n",
       "1  Serving the metropolitan Baltimore area and th...   \n",
       "2  VSS Catholic Communications is dedicated to an...   \n",
       "3  The mission of the Utah Symphony & Opera is to...   \n",
       "4  Funded solely by the footwear industry, Two Te...   \n",
       "\n",
       "                                              motto  score state  \n",
       "0  Great communities. Working lands. Iconic Places.  91.94    OR  \n",
       "1                  88.1 FM -. Your NPR News Station  85.59    MD  \n",
       "2                     Spirit Catholic Radio Network  76.80    NE  \n",
       "3          Engaging, educating, and enriching lives  91.95    UT  \n",
       "4                     Shoepeople Helping Shoepeople  90.26    MA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_navigator_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(charity_navigator_df.groupby('category').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 11 Categories Total\n",
    "## A \"Random Guess\" Baseline is 1/11 = 9.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = charity_navigator_df[:6000]\n",
    "char_desc_trimmed = []\n",
    "for doc in train_df['description']:\n",
    "    if len(doc) >= 200:\n",
    "        char_desc_trimmed.append(doc)\n",
    "char_desc_trimmed = np.array(char_desc_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5616"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_desc_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Processing Training Corpus\n",
      "2. Creating Index from Training Corpus\n",
      "3. Starting Test Corpus Similarity Analysis\n",
      "\n",
      "First Recommendation Score: 11.75 %\n",
      "Second Recommendation Score: 12.3 %\n",
      "Third Recommendation Score: 11.3 %\n"
     ]
    }
   ],
   "source": [
    "train_df = charity_navigator_df[:6000]\n",
    "test_df = charity_navigator_df[-2000:]\n",
    "\n",
    "find_similar_charities(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(charity_navigator_df,test_size = 0.30)\n",
    "\n",
    "find_similar_charities(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(charity_navigator_df,test_size = 0.25)\n",
    "\n",
    "find_similar_charities(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Processing Training Corpus\n",
      "2. Creating Index from Training Corpus\n",
      "3. Starting Test Corpus Similarity Analysis\n",
      "\n",
      "First Recommendation Score: 12.31 %\n",
      "Second Recommendation Score: 13.08 %\n",
      "Third Recommendation Score: 13.14 %\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'math' has no attribute 'round'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-fe3e6fc5b77d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharity_navigator_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfind_similar_charities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-e68ec6af86ba>\u001b[0m in \u001b[0;36mfind_similar_charities\u001b[0;34m(train_df, test_df)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Third Recommendation Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_rec_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"AVG Recommendation Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_rec_score\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msecond_rec_score\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mthird_rec_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'math' has no attribute 'round'"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(charity_navigator_df,test_size = 0.20)\n",
    "\n",
    "find_similar_charities(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
